\section{Introduction: The Expert Paradox}

\subsection{The Mirror of Our Misconceptions}

In the current day, we experts in our respective fields tend to hold a highly simplified, even naive concept of other subject matter experts: someone who can apply a large set of formulas; someone knowing the ``right'' distributions or gradients for specific values; someone who knows how those gradients evolved over time; someone able to apply the appropriate ``context,'' as one value at one point in time may be good but in a different context at another time not.

For ourselves, we would always claim: there is far more that cannot be extracted from our heads. Let us also set aside the comfortable illusion of our own rationality.

This simplified conception of the SME is the direct result of how our organizations and systems have arranged themselves perfectly around the Data-Information-Knowledge-Wisdom (DIKW) pyramid. We have been trained to perceive wisdom as directly derivable from data, aggregated through formulas and algorithms into information and knowledge. This represents a dangerous oversimplification now deeply embedded in our society, despite mounting evidence of its fundamental inadequacy.

The evidence against formula-based expertise is overwhelming. \citet{tetlock2005} comprehensive study of political experts found that most perform barely better than random chance, often surpassed by simple base-rate algorithms. As he observes, ``All one need do is constantly predict the higher base rate outcome and---like the proverbial broken clock---one will look good'' \citep{tetlock2005}. Yet real expertise requires knowing precisely when the base rate doesn't apply---what Gigerenzer calls ``ecological rationality,'' the ability to match the right tool from an ``adaptive toolbox'' to specific environmental structures \citep{gigerenzer2001}.

\citet{kahneman2009}, despite approaching from opposing theoretical positions, converged on two critical conditions for valid expert intuition: an environment regular enough to be predictable and prolonged practice with clear feedback loops. Our systems pretend expertise is merely pattern recognition---what \citet{klein1993} calls ``recognition-primed decision making''---while ignoring that these patterns emerge from years of embodied experience with ``prototypical situations'' that cannot be algorithmically specified.

Most fundamentally, the Dreyfus brothers' model reveals that true expertise operates through ``intuition and know-how\ldots understanding that effortlessly occurs upon seeing similarities with previous experiences'' \citep{pena2010}. This cannot be formalized because, as \citet{polanyi1966} crystallized in his oft-cited maxim: ``We know more than we can tell.'' \citet{collins2010} extends this insight, identifying three forms of tacit knowledge---embodied, social, and relational---that remain ``impossible to make explicit in machines.''

\subsection{The Visceral Evidence}

Despite this mountain of scholarship, we need only look to everyday experience for proof. We all understand that a master chef represents more than a recipe repository. The chef doesn't merely know that béarnaise requires three egg yolks at 65°C---they can feel when the emulsion threatens to break, smell when the tarragon overpowers, adjust for humidity affecting reduction rates. This exemplifies what medieval guilds once cultivated through decade-long apprenticeships: what the Greeks called \emph{techne}---embodied craft knowledge that fundamentally resists extraction.

As \citet{morgan2014} notes regarding expert elicitation: ``The best experts have comprehensive mental models of all of the various factors that may influence the value of an uncertain quantity.'' But these mental models aren't flowcharts---they're multi-dimensional cognitive architectures built through thousands of micro-adjustments, failures, and recoveries that no curriculum can simulate.

Consider a final example everyone can relate to: would you prefer treatment from a young physician with 1,000 micro-credential badges or from someone who has practiced for decades? The micro-credentialed physician knows the distributions---which symptoms correlate with which conditions at what confidence intervals. But the experienced physician possesses what \citet{endsley1995} calls genuine ``situation awareness'': the integration of perception, comprehension of meaning including historical evolution, and projection to future states. They recognize when a patient doesn't fit the distribution, when context invalidates the algorithm, when an unusual constellation of symptoms points toward something the guidelines haven't considered.

This represents \citet{taleb2007} Black Swan blindness in reverse: expertise isn't knowing more distributions but recognizing when you've left the domain where distributions apply. Taleb himself demonstrated this principle by generating billions in returns while Nobel laureate economists at Long-Term Capital Management---armed with the most sophisticated formulas ever developed---lost everything. The sphere-thinker defeated the vector-optimizers when reality departed from the models.

\subsection{The Question Before Us}

The DIKW pyramid represents what \citet{dreyfus1979} identified as the fundamental error of artificial intelligence: the assumption that expertise constitutes ``symbolic manipulation'' rather than situated, embodied competence. This reductionist epistemology has colonized our institutional structures, creating vectorized knowledge systems that systematically eliminate the spherical cognitive architectures necessary for navigating complexity.

Scattered researchers at the disciplinary periphery have begun noticing energetic dimensions---management scholars exploring ``knowledge entropy'' \citep{bratianu2020}, neuroscientists measuring cognitive metabolic costs \citep{wiehler2022}, physicists proposing information-energy equivalence \citep{stonier1996}. Yet these insights remain unintegrated, like astronomers before Copernicus observing planetary retrograde motion without recognizing the heliocentric pattern. The core of knowledge management theory continues operating as if cognition were costless computation rather than energy-intensive biological work.

We stand at a critical juncture. Having spent a century training humans to think like machines---to process information through standardized channels, to optimize for measurable outputs, to collapse multidimensional understanding into linear decision trees---we now face the arrival of actual machines that perform these simplified functions more efficiently than their biological precursors.

The core question this paper addresses is not whether artificial intelligence will replace human expertise, but rather: \textbf{How did we transform human cognition into something so readily replaceable?} The answer lies in a 500-year project to reshape spherical human consciousness into vectors suitable for industrial processing---a project that has reached its thermodynamic conclusion just as its silicon beneficiaries arrive to claim their inheritance.

\subsection{Approach and Structure}

To answer this question, this paper employs a novel analytical framework that treats knowledge not as information but as a thermodynamic system requiring continuous energy investment to maintain its organizational complexity. While isolated researchers have begun exploring energetic dimensions of cognition---\citet{bratianu2020} on ``knowledge entropy,'' neuroscientists measuring metabolic costs \citep{jamadar2025}, and physicists theorizing information-energy equivalence \citep{stonier1996}---these insights remain trapped in disciplinary silos, preventing synthesis into a unified theory of cognitive thermodynamics. This paper bridges these fragmented recognitions to reveal the systematic energetic basis underlying all knowledge systems.

We synthesize three methodological approaches: (1) historical archaeology of knowledge systems, tracing the systematic reduction from 10+ distinct forms of wisdom in ancient Greece to today's DIKW pyramid; (2) critical analysis of what we term ``confession literature''---papers from education, management consulting, and platform design that inadvertently document their own role in cognitive standardization; and (3) thermodynamic modeling that reveals why knowledge systems collapse without sustained energy investment, explaining both institutional decay and the ease with which AI systems can replicate energy-depleted cognitive functions.

Our analysis proceeds through eight interconnected arguments. Section 2 situates our thesis within existing literature on expertise, cognitive capitalism, and knowledge management, revealing a blind spot in current scholarship regarding the energetic basis of knowledge. Section 3 presents our methodology in detail, explaining how thermodynamic principles apply to cognitive systems. Section 4 provides historical evidence for the deliberate transformation from sphere to vector cognition, identifying key inflection points from medieval guilds through the Bologna Process. Section 5 examines contemporary evidence, including the micro-credentialization movement and competency-based education as the approach to thermodynamic zero. Section 6 reveals how AI architecture mirrors educational standardization---not coincidentally but as the logical culmination of century-long preparation. Section 7 proposes principles for reconstructing sphere-based cognitive systems that resist algorithmic extraction. Section 8 explores the implications of our thermodynamic framework for education, organizations, and civilization. The conclusion considers whether genuine choice remains between accepting vectorized dissolution or investing in spherical reconstruction.

This is not merely an academic exercise. As institutions worldwide face cascading failures of expertise---from financial crises unforeseen by economists to pandemics mismanaged by standardized protocols---understanding how we engineered our own cognitive obsolescence becomes essential for determining whether human judgment retains any irreducible value in an algorithmic age.
